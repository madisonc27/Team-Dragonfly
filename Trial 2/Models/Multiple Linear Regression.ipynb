{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd59b257",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "First we will use multiple linear regression to predict the rating based on the features such as region and roast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3df01a4",
   "metadata": {},
   "source": [
    "## Uploading the data and creating a train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0402cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad320c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first load the data\n",
    "coffee = pd.read_csv('../data/one_hot_coffee.csv')\n",
    "coffee = coffee.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9c75f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## next perform the train test split\n",
    "coffee_train, coffee_test = train_test_split(coffee,\n",
    "                                            shuffle=True,\n",
    "                                            random_state=47,\n",
    "                                            test_size = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67a625a",
   "metadata": {},
   "source": [
    "## Exploration and Creating a Baseline\n",
    "Here are some exploratory OLS metrics with code courtesy of our mentor Andrew Castillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11d1c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29afc89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>rating</td>      <th>  R-squared:         </th> <td>   0.362</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.359</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   117.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 03 Jun 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:33:22</td>     <th>  Log-Likelihood:    </th> <td> -9602.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3741</td>      <th>  AIC:               </th> <td>1.924e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3722</td>      <th>  BIC:               </th> <td>1.936e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                  <td>   75.7545</td> <td>    0.086</td> <td>  876.875</td> <td> 0.000</td> <td>   75.585</td> <td>   75.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_africa_arabia</th>   <td>    1.8811</td> <td>    0.146</td> <td>   12.862</td> <td> 0.000</td> <td>    1.594</td> <td>    2.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_caribbean</th>       <td>   -1.7335</td> <td>    0.752</td> <td>   -2.306</td> <td> 0.021</td> <td>   -3.207</td> <td>   -0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_central_america</th> <td>    0.4314</td> <td>    0.178</td> <td>    2.428</td> <td> 0.015</td> <td>    0.083</td> <td>    0.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_hawaii</th>          <td>    0.9310</td> <td>    0.393</td> <td>    2.367</td> <td> 0.018</td> <td>    0.160</td> <td>    1.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_asia_pacific</th>    <td>    0.2260</td> <td>    0.211</td> <td>    1.070</td> <td> 0.285</td> <td>   -0.188</td> <td>    0.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>region_south_america</th>   <td>    0.0784</td> <td>    0.210</td> <td>    0.373</td> <td> 0.709</td> <td>   -0.333</td> <td>    0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_espresso</th>          <td>    1.7595</td> <td>    0.155</td> <td>   11.364</td> <td> 0.000</td> <td>    1.456</td> <td>    2.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_organic</th>           <td>   -0.0346</td> <td>    0.239</td> <td>   -0.144</td> <td> 0.885</td> <td>   -0.504</td> <td>    0.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_fair_trade</th>        <td>    0.0968</td> <td>    0.294</td> <td>    0.329</td> <td> 0.742</td> <td>   -0.481</td> <td>    0.674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_decaffeinated</th>     <td>    0.2582</td> <td>    0.535</td> <td>    0.483</td> <td> 0.629</td> <td>   -0.791</td> <td>    1.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_pod_capsule</th>       <td>   -1.8647</td> <td>    0.300</td> <td>   -6.220</td> <td> 0.000</td> <td>   -2.452</td> <td>   -1.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_blend</th>             <td>    0.2236</td> <td>    0.192</td> <td>    1.163</td> <td> 0.245</td> <td>   -0.153</td> <td>    0.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>type_estate</th>            <td>    0.6074</td> <td>    0.181</td> <td>    3.357</td> <td> 0.001</td> <td>    0.253</td> <td>    0.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dark</th>                   <td>    9.5367</td> <td>    0.197</td> <td>   48.392</td> <td> 0.000</td> <td>    9.150</td> <td>    9.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Light</th>                  <td>   15.5745</td> <td>    0.169</td> <td>   91.923</td> <td> 0.000</td> <td>   15.242</td> <td>   15.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Medium</th>                 <td>   14.0938</td> <td>    0.102</td> <td>  138.515</td> <td> 0.000</td> <td>   13.894</td> <td>   14.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Medium-Dark</th>            <td>   11.5819</td> <td>    0.125</td> <td>   92.782</td> <td> 0.000</td> <td>   11.337</td> <td>   11.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Medium-Light</th>           <td>   15.4516</td> <td>    0.103</td> <td>  149.507</td> <td> 0.000</td> <td>   15.249</td> <td>   15.654</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Very Dark</th>              <td>    9.5162</td> <td>    0.230</td> <td>   41.303</td> <td> 0.000</td> <td>    9.064</td> <td>    9.968</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1929.847</td> <th>  Durbin-Watson:     </th> <td>   2.016</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>21384.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-2.206</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>13.850</td>  <th>  Cond. No.          </th> <td>6.29e+15</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.35e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 rating   R-squared:                       0.362\n",
       "Model:                            OLS   Adj. R-squared:                  0.359\n",
       "Method:                 Least Squares   F-statistic:                     117.3\n",
       "Date:                Fri, 03 Jun 2022   Prob (F-statistic):               0.00\n",
       "Time:                        16:33:22   Log-Likelihood:                -9602.3\n",
       "No. Observations:                3741   AIC:                         1.924e+04\n",
       "Df Residuals:                    3722   BIC:                         1.936e+04\n",
       "Df Model:                          18                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "const                     75.7545      0.086    876.875      0.000      75.585      75.924\n",
       "region_africa_arabia       1.8811      0.146     12.862      0.000       1.594       2.168\n",
       "region_caribbean          -1.7335      0.752     -2.306      0.021      -3.207      -0.260\n",
       "region_central_america     0.4314      0.178      2.428      0.015       0.083       0.780\n",
       "region_hawaii              0.9310      0.393      2.367      0.018       0.160       1.702\n",
       "region_asia_pacific        0.2260      0.211      1.070      0.285      -0.188       0.640\n",
       "region_south_america       0.0784      0.210      0.373      0.709      -0.333       0.490\n",
       "type_espresso              1.7595      0.155     11.364      0.000       1.456       2.063\n",
       "type_organic              -0.0346      0.239     -0.144      0.885      -0.504       0.435\n",
       "type_fair_trade            0.0968      0.294      0.329      0.742      -0.481       0.674\n",
       "type_decaffeinated         0.2582      0.535      0.483      0.629      -0.791       1.307\n",
       "type_pod_capsule          -1.8647      0.300     -6.220      0.000      -2.452      -1.277\n",
       "type_blend                 0.2236      0.192      1.163      0.245      -0.153       0.601\n",
       "type_estate                0.6074      0.181      3.357      0.001       0.253       0.962\n",
       "Dark                       9.5367      0.197     48.392      0.000       9.150       9.923\n",
       "Light                     15.5745      0.169     91.923      0.000      15.242      15.907\n",
       "Medium                    14.0938      0.102    138.515      0.000      13.894      14.293\n",
       "Medium-Dark               11.5819      0.125     92.782      0.000      11.337      11.827\n",
       "Medium-Light              15.4516      0.103    149.507      0.000      15.249      15.654\n",
       "Very Dark                  9.5162      0.230     41.303      0.000       9.064       9.968\n",
       "==============================================================================\n",
       "Omnibus:                     1929.847   Durbin-Watson:                   2.016\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            21384.432\n",
       "Skew:                          -2.206   Prob(JB):                         0.00\n",
       "Kurtosis:                      13.850   Cond. No.                     6.29e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.35e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sm = sm.add_constant(coffee_train[predictors])\n",
    "mlr = sm.OLS(coffee_train.rating,X_sm)\n",
    "mlr.fit().summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a98dac",
   "metadata": {},
   "source": [
    "For a baseline model to compare our methods to, we will use a constant prediction of the the average rating for the coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93e8107",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.43704891740177\n"
     ]
    }
   ],
   "source": [
    "## make a baseline, which we will simply take to be the mean of the ratings\n",
    "baseline = coffee_train['rating'].mean()\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82f9c4",
   "metadata": {},
   "source": [
    "## Creating MLR Model and running cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "428d0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e2c7a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a list of predictor variables\n",
    "predictors = ['region_africa_arabia', 'region_caribbean',\n",
    "       'region_central_america', 'region_hawaii', 'region_asia_pacific',\n",
    "       'region_south_america', 'type_espresso', 'type_organic',\n",
    "       'type_fair_trade', 'type_decaffeinated', 'type_pod_capsule',\n",
    "       'type_blend', 'type_estate', 'Dark', 'Light', 'Medium', 'Medium-Dark', 'Medium-Light', 'Very Dark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9890996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform cross validation for the linear regression model\n",
    "\n",
    "splits = 5\n",
    "kfold = KFold(n_splits=splits, shuffle=True, random_state=413)\n",
    "\n",
    "reg = LinearRegression(copy_X = True)\n",
    "mse = np.empty(splits)\n",
    "mae = np.empty(splits)\n",
    "\n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(coffee_train):\n",
    "    coffee_train_train = coffee_train.iloc[train_index]\n",
    "    coffee_holdout = coffee_train.iloc[test_index]\n",
    "\n",
    "    reg.fit(coffee_train_train[predictors], \n",
    "            coffee_train_train['rating'])\n",
    "    \n",
    "    preds = reg.predict(coffee_train_train[predictors])\n",
    "    \n",
    "    mse[i] = mean_squared_error(coffee_train_train['rating'], preds)\n",
    "    mae[i] = mean_absolute_error(coffee_train_train['rating'], preds)\n",
    "    \n",
    "    i = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d06a32c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the predictions for baseline\n",
    "preds_baseline = baseline * np.ones(len(coffee_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4379adeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average cross validation mean squared error for multiple linear regression is 9.924867305555471\n",
      "The mean squared error for the baseline is 15.564935851389496\n"
     ]
    }
   ],
   "source": [
    "## check the average mean squared error and compare to baseline\n",
    "mse_baseline = mean_squared_error(coffee_train['rating'], preds_baseline)\n",
    "print(\"The average cross validation mean squared error for multiple linear regression is\", np.mean(mse))\n",
    "print(\"The mean squared error for the baseline is\", mse_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c480d97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average cross validation mean absolute error for multiple linear regression is 2.1024140116348797\n",
      "The mean absolute error for the baseline is 2.854659147739123\n"
     ]
    }
   ],
   "source": [
    "## check the average mean squared error and compare to baseline\n",
    "mae_baseline = mean_absolute_error(coffee_train['rating'], preds_baseline)\n",
    "print(\"The average cross validation mean absolute error for multiple linear regression is\", np.mean(mae))\n",
    "print(\"The mean absolute error for the baseline is\", mae_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eb684c",
   "metadata": {},
   "source": [
    "Our MLR model appears to be performing well on the training set compared to the baseline model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc9a423",
   "metadata": {},
   "source": [
    "## Running the model on the test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22870066",
   "metadata": {},
   "source": [
    "Here we run the MLR model on the prior created test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aad93a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(coffee_train[predictors], coffee_train.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8569e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average cross validation mean squared error for multiple linear regression is 8.94406274648813\n",
      "The average cross validation mean absolute error for multiple linear regression is 2.081188234508547\n"
     ]
    }
   ],
   "source": [
    "pred = reg.predict(coffee_test[predictors])\n",
    "test_mse = mean_squared_error(coffee_test.rating,pred)\n",
    "test_mae = mean_absolute_error(coffee_test.rating,pred)\n",
    "\n",
    "print(\"The average cross validation mean squared error for multiple linear regression is\", test_mse)\n",
    "print(\"The average cross validation mean absolute error for multiple linear regression is\", test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a81eb787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error for the baseline is 13.711274060947115\n",
      "The mean absolute error for the baseline is 2.7539702122701315\n"
     ]
    }
   ],
   "source": [
    "preds_baseline = baseline * np.ones(len(coffee_test))\n",
    "\n",
    "mse_baseline = mean_squared_error(coffee_test['rating'], preds_baseline)\n",
    "mae_baseline = mean_absolute_error(coffee_test['rating'], preds_baseline)\n",
    "print(\"The mean squared error for the baseline is\", mse_baseline)\n",
    "print(\"The mean absolute error for the baseline is\", mae_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46e9437",
   "metadata": {},
   "source": [
    "## Saving the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa50b611",
   "metadata": {},
   "source": [
    "Now we save our test results.  The code below was run to create a csv file that contains the MSE and MAE for the baseline model and the MLR model. But it is commented out now as to not overwrite the created file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e914c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed4c9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('testing_results.csv', mode='w') as coffee_file:\n",
    "#    results_writer = csv.writer(coffee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#    \n",
    "#    results_writer.writerow(['Test', 'MSE', 'MAE'])\n",
    "#    results_writer.writerow(['Baseline', mse_baseline, mae_baseline])\n",
    "#    results_writer.writerow(['MLR', test_mse, test_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88765b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
